{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNeUtrLCvpZr"
      },
      "source": [
        "# **Setting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inDhYVjo5u9h",
        "outputId": "55fc47df-a997-4e0a-a3b2-d6d8dd91ae62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost==1.6.1\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost==1.6.1) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost==1.6.1) (1.16.1)\n",
            "Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.9/192.9 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 3.0.4\n",
            "    Uninstalling xgboost-3.0.4:\n",
            "      Successfully uninstalled xgboost-3.0.4\n",
            "Successfully installed xgboost-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost==1.6.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLmjMf0qr9ey"
      },
      "source": [
        "# **Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf5_zmTbl_KR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import sklearn\n",
        "import xgboost\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.cluster import KMeans\n",
        "import random as rn\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dajjud7DmEn3"
      },
      "source": [
        "# **Utilities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiH8hJSjmBuq"
      },
      "outputs": [],
      "source": [
        "def smape(gt, preds):\n",
        "    gt= np.array(gt)\n",
        "    preds = np.array(preds)\n",
        "    v = 2 * abs(preds - gt) / (abs(preds) + abs(gt))\n",
        "    score = np.mean(v) * 100\n",
        "    return score\n",
        "\n",
        "def weighted_mse(alpha = 1):\n",
        "    def weighted_mse_fixed(label, pred):\n",
        "        residual = (label - pred).astype(\"float\")\n",
        "        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n",
        "        hess = np.where(residual>0, 2*alpha, 2.0)\n",
        "        return grad, hess\n",
        "    return weighted_mse_fixed\n",
        "\n",
        "def custom_smape(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'custom_smape', np.mean(2 * abs(preds - labels) / (abs(preds) + abs(labels))) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Config**"
      ],
      "metadata": {
        "id": "dR-XqMHzhbu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_1rrrsFyE-o"
      },
      "outputs": [],
      "source": [
        "np.random.seed(2025)\n",
        "rn.seed(2025)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "KFOLD_SPLITS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLiDPM-yyE-u",
        "outputId": "f7658947-b1ce-43ec-e1b6-65717f8ca32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "except:\n",
        "    DATA_DIR = \"./data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQv6915il2SD"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIyDzxesl2mj"
      },
      "outputs": [],
      "source": [
        "def Preprocessing(summer = False, cluster = False):\n",
        "    train          = pd.read_csv(f'{DATA_DIR}/train.csv', encoding='utf-8-sig')\n",
        "    test           = pd.read_csv(f'{DATA_DIR}/test.csv',  encoding='utf-8-sig')\n",
        "    building_info  = pd.read_csv(f'{DATA_DIR}/building_info.csv', encoding='utf-8-sig')\n",
        "\n",
        "    train = train.rename(columns={\n",
        "        '건물번호': 'building_number',\n",
        "        '일시': 'date_time',\n",
        "        '기온(°C)': 'temperature',\n",
        "        '강수량(mm)': 'rainfall',\n",
        "        '풍속(m/s)': 'windspeed',\n",
        "        '습도(%)': 'humidity',\n",
        "        '일조(hr)': 'sunshine',\n",
        "        '일사(MJ/m2)': 'solar_radiation',\n",
        "        '전력소비량(kWh)': 'power_consumption'\n",
        "    })\n",
        "    train.drop('num_date_time', axis = 1, inplace=True)\n",
        "\n",
        "    test = test.rename(columns={\n",
        "        '건물번호': 'building_number',\n",
        "        '일시': 'date_time',\n",
        "        '기온(°C)': 'temperature',\n",
        "        '강수량(mm)': 'rainfall',\n",
        "        '풍속(m/s)': 'windspeed',\n",
        "        '습도(%)': 'humidity',\n",
        "        '일조(hr)': 'sunshine',\n",
        "        '일사(MJ/m2)': 'solar_radiation',\n",
        "        '전력소비량(kWh)': 'power_consumption'\n",
        "    })\n",
        "    test.drop('num_date_time', axis = 1, inplace=True)\n",
        "\n",
        "    building_info = building_info.rename(columns={\n",
        "        '건물번호': 'building_number',\n",
        "        '건물유형': 'building_type',\n",
        "        '연면적(m2)': 'total_area',\n",
        "        '냉방면적(m2)': 'cooling_area',\n",
        "        '태양광용량(kW)': 'solar_power_capacity',\n",
        "        'ESS저장용량(kWh)': 'ess_capacity',\n",
        "        'PCS용량(kW)': 'pcs_capacity'\n",
        "    })\n",
        "\n",
        "    translation_dict = {\n",
        "        '건물기타': 'Other Buildings',\n",
        "        '공공': 'Public',\n",
        "        '학교': 'University',\n",
        "        '백화점': 'Department Store',\n",
        "        '병원': 'Hospital',\n",
        "        '상용': 'Commercial',\n",
        "        '아파트': 'Apartment',\n",
        "        '연구소': 'Research Institute',\n",
        "        'IDC(전화국)': 'IDC',\n",
        "        '호텔': 'Hotel'\n",
        "    }\n",
        "\n",
        "    building_info['building_type'] = building_info['building_type'].replace(translation_dict)\n",
        "    building_info['solar_power_utility'] = np.where(building_info.solar_power_capacity !='-',1,0)\n",
        "    building_info['ess_utility'] = np.where(building_info.ess_capacity !='-',1,0)\n",
        "\n",
        "    train = pd.merge(train, building_info, on='building_number', how='left')\n",
        "    test = pd.merge(test, building_info, on='building_number', how='left')\n",
        "\n",
        "    train['date_time'] = pd.to_datetime(train['date_time'], format='%Y%m%d %H')\n",
        "\n",
        "    # Datetime\n",
        "    train['hour'] = train['date_time'].dt.hour\n",
        "    train['day'] = train['date_time'].dt.day\n",
        "    train['month'] = train['date_time'].dt.month\n",
        "    train['day_of_week'] = train['date_time'].dt.dayofweek\n",
        "    test['date_time'] = pd.to_datetime(test['date_time'], format='%Y%m%d %H')\n",
        "\n",
        "    test['hour'] = test['date_time'].dt.hour\n",
        "    test['day'] = test['date_time'].dt.day\n",
        "    test['month'] = test['date_time'].dt.month\n",
        "    test['day_of_week'] = test['date_time'].dt.dayofweek\n",
        "\n",
        "    # Calculate 'day_temperature'\n",
        "    def calculate_day_values(dataframe, target_column, output_column, aggregation_func):\n",
        "        result_dict = {}\n",
        "\n",
        "        grouped_temp = dataframe.groupby(['building_number', 'month', 'day'])[target_column].agg(aggregation_func)\n",
        "\n",
        "        for (building, month, day), value in grouped_temp.items():\n",
        "            result_dict.setdefault(building, {}).setdefault(month, {})[day] = value\n",
        "\n",
        "        dataframe[output_column] = [\n",
        "            result_dict.get(row['building_number'], {}).get(row['month'], {}).get(row['day'], None)\n",
        "            for _, row in dataframe.iterrows()\n",
        "        ]\n",
        "\n",
        "    train['day_max_temperature'] = 0.0\n",
        "    train['day_mean_temperature'] = 0.0\n",
        "\n",
        "    calculate_day_values(train, 'temperature', 'day_max_temperature', 'max')\n",
        "    calculate_day_values(train, 'temperature', 'day_mean_temperature', 'mean')\n",
        "    calculate_day_values(train, 'temperature', 'day_min_temperature', 'min')\n",
        "\n",
        "    train['day_temperature_range'] = train['day_max_temperature'] - train['day_min_temperature']\n",
        "\n",
        "    calculate_day_values(test, 'temperature', 'day_max_temperature', 'max')\n",
        "    calculate_day_values(test, 'temperature', 'day_mean_temperature', 'mean')\n",
        "    calculate_day_values(test, 'temperature', 'day_min_temperature', 'min')\n",
        "\n",
        "    test['day_temperature_range'] = test['day_max_temperature'] - test['day_min_temperature']\n",
        "\n",
        "    # Outlier\n",
        "    outlier_idx = train.index[train['power_consumption'] == 0].tolist()\n",
        "\n",
        "    train.drop(index=outlier_idx, inplace=True)\n",
        "\n",
        "    outlier_df = pd.read_excel(f'{DATA_DIR}/outlier (4).xlsx')\n",
        "    outlier_df['date'] = pd.to_datetime(outlier_df['date'], format='%Y%m%d')\n",
        "\n",
        "    initial_train_rows = train.shape[0]\n",
        "\n",
        "    for _, row in outlier_df.iterrows():\n",
        "        building_num = row['num']\n",
        "        outlier_date = row['date'].date()\n",
        "\n",
        "        indices_to_drop = train[(train['building_number'] == building_num) &\n",
        "                                (train['date_time'].dt.date == outlier_date)].index\n",
        "\n",
        "        train.drop(indices_to_drop, inplace=True)\n",
        "\n",
        "    rows_dropped_from_outlier_file = initial_train_rows - train.shape[0]\n",
        "\n",
        "    # Holiday\n",
        "    holi_weekday = ['2024-06-06', '2024-08-15']\n",
        "\n",
        "    train['holiday'] = np.where((train.day_of_week >= 5) | (train.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0)\n",
        "    test['holiday'] = np.where((test.day_of_week >= 5) | (test.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0)\n",
        "\n",
        "    # Datetime Fourier transform\n",
        "    train['sin_hour'] = np.sin(2 * np.pi * train['hour']/23.0)\n",
        "    train['cos_hour'] = np.cos(2 * np.pi * train['hour']/23.0)\n",
        "    test['sin_hour'] = np.sin(2 * np.pi * test['hour']/23.0)\n",
        "    test['cos_hour'] = np.cos(2 * np.pi * test['hour']/23.0)\n",
        "\n",
        "    train['sin_date'] = -np.sin(2 * np.pi * (train['month']+train['day']/31)/12)\n",
        "    train['cos_date'] = -np.cos(2 * np.pi * (train['month']+train['day']/31)/12)\n",
        "    test['sin_date'] = -np.sin(2 * np.pi * (test['month']+test['day']/31)/12)\n",
        "    test['cos_date'] = -np.cos(2 * np.pi * (test['month']+test['day']/31)/12)\n",
        "\n",
        "    train['sin_month'] = -np.sin(2 * np.pi * train['month']/12.0)\n",
        "    train['cos_month'] = -np.cos(2 * np.pi * train['month']/12.0)\n",
        "    test['sin_month'] = -np.sin(2 * np.pi * test['month']/12.0)\n",
        "    test['cos_month'] = -np.cos(2 * np.pi * test['month']/12.0)\n",
        "\n",
        "    train['sin_dayofweek'] = -np.sin(2 * np.pi * (train['day_of_week']+1)/7.0)\n",
        "    train['cos_dayofweek'] = -np.cos(2 * np.pi * (train['day_of_week']+1)/7.0)\n",
        "    test['sin_dayofweek'] = -np.sin(2 * np.pi * (test['day_of_week']+1)/7.0)\n",
        "    test['cos_dayofweek'] = -np.cos(2 * np.pi * (test['day_of_week']+1)/7.0)\n",
        "\n",
        "    # Summer feature\n",
        "    if summer == True:\n",
        "        def summer_cos(date):\n",
        "            start_date = datetime.strptime(\"2024-06-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
        "            end_date = datetime.strptime(\"2024-09-14 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            period = (end_date - start_date).total_seconds()\n",
        "\n",
        "            return math.cos(2 * math.pi * (date - start_date).total_seconds() / period)\n",
        "\n",
        "        def summer_sin(date):\n",
        "            start_date = datetime.strptime(\"2024-06-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
        "            end_date = datetime.strptime(\"2024-09-14 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            period = (end_date - start_date).total_seconds()\n",
        "\n",
        "            return math.sin(2 * math.pi * (date - start_date).total_seconds() / period)\n",
        "\n",
        "        train['summer_cos'] = train['date_time'].apply(summer_cos)\n",
        "        train['summer_sin'] = train['date_time'].apply(summer_sin)\n",
        "\n",
        "        test['summer_cos'] = test['date_time'].apply(summer_cos)\n",
        "        test['summer_sin'] = test['date_time'].apply(summer_sin)\n",
        "\n",
        "    # CDH\n",
        "    def CDH(xs):\n",
        "        cumsum = np.cumsum(xs - 26)\n",
        "        return np.concatenate((cumsum[:11], cumsum[11:] - cumsum[:-11]))\n",
        "\n",
        "    def calculate_and_add_cdh(dataframe):\n",
        "        cdhs = []\n",
        "        for i in range(1, 101):\n",
        "            temp = dataframe[dataframe['building_number'] == i]['temperature'].values\n",
        "            cdh = CDH(temp)\n",
        "            cdhs.append(cdh)\n",
        "        return np.concatenate(cdhs)\n",
        "\n",
        "    train['CDH'] = calculate_and_add_cdh(train)\n",
        "    test['CDH'] = calculate_and_add_cdh(test)\n",
        "    train['THI'] = 9/5*train['temperature'] - 0.55*(1-train['humidity']/100)*(9/5*train['humidity']-26)+32\n",
        "    test['THI'] = 9/5*test['temperature'] - 0.55*(1-test['humidity']/100)*(9/5*test['humidity']-26)+32\n",
        "    train['WCT'] = 13.12 + 0.6125*train['temperature'] - 11.37*(train['windspeed']**\n",
        "                                                                0.16) + 0.3965*(train['windspeed']**0.16)*train['temperature']\n",
        "    test['WCT'] = 13.12 + 0.6125*test['temperature'] - 11.37*(test['windspeed']**\n",
        "                                                                0.16) + 0.3965*(test['windspeed']**0.16)*test['temperature']\n",
        "\n",
        "    # Calculate 'power_consumption'\n",
        "    power_mean = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour', 'day_of_week'], aggfunc=np.mean).reset_index()\n",
        "    power_mean.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_mean']\n",
        "\n",
        "    power_std = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour', 'day_of_week'], aggfunc=np.std).reset_index()\n",
        "    power_std.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_std']\n",
        "\n",
        "    power_hour_mean = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour'], aggfunc=np.mean).reset_index()\n",
        "    power_hour_mean.columns = ['building_number', 'hour', 'hour_mean']\n",
        "\n",
        "    power_hour_std = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour'], aggfunc=np.std).reset_index()\n",
        "    power_hour_std.columns = ['building_number', 'hour', 'hour_std']\n",
        "\n",
        "    train = train.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "    test = test.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "\n",
        "    train = train.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "    test = test.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
        "\n",
        "    train = train.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
        "    test = test.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
        "\n",
        "    train = train.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
        "    test = test.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
        "\n",
        "    train = train.reset_index(drop=True)\n",
        "\n",
        "    # Cluster\n",
        "    if cluster == True:\n",
        "        pivot_table = train.pivot_table(\n",
        "            values='power_consumption',\n",
        "            index='building_number',\n",
        "            columns=['day_of_week', 'hour'],\n",
        "            aggfunc='mean'\n",
        "        ).fillna(0)\n",
        "\n",
        "        pivot_table.columns = [f'dow_{dow}_hour_{hour}' for (dow, hour) in pivot_table.columns]\n",
        "\n",
        "        k = 5\n",
        "        kmeans = KMeans(n_clusters=k, random_state=2025, n_init=10)\n",
        "        clusters = kmeans.fit_predict(pivot_table)\n",
        "\n",
        "        building_info = building_info.set_index('building_number')\n",
        "        building_info['cluster'] = pd.Series(clusters, index=pivot_table.index)\n",
        "        building_info = building_info.reset_index()\n",
        "\n",
        "        train = pd.merge(train, building_info[['building_number', 'cluster']], on='building_number', how='left')\n",
        "        test = pd.merge(test, building_info[['building_number', 'cluster']], on='building_number', how='left')\n",
        "\n",
        "        cluster_counts = building_info['cluster'].value_counts().sort_index()\n",
        "        print(\"Cluster-wise building count:\")\n",
        "        print(cluster_counts)\n",
        "\n",
        "        total_buildings = building_info['building_number'].nunique()\n",
        "        print(\"\\nTotal number of buildings:\", total_buildings)\n",
        "\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlsJlzbeo_MM"
      },
      "source": [
        "# **No Summer Feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzPFOMg_o_MN"
      },
      "outputs": [],
      "source": [
        "train, test = Preprocessing(False, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88bbA4n9o_MN"
      },
      "outputs": [],
      "source": [
        "X = train.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity',\n",
        "                'power_consumption','rainfall', 'sunshine', 'solar_radiation',\n",
        "                'hour','day','month','day_of_week','date_time'],axis =1 )\n",
        "\n",
        "Y = train[['building_type','power_consumption']]\n",
        "\n",
        "test_X = test.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity','rainfall',\n",
        "                   'hour','month','day_of_week','day','date_time'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1h8yGyAo_MN"
      },
      "outputs": [],
      "source": [
        "type_list = []\n",
        "for value in train.building_type.values:\n",
        "    if value not in type_list:\n",
        "        type_list.append(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS44VPDHo_MN"
      },
      "outputs": [],
      "source": [
        "max_depth_dict = {\n",
        "    'Other Buildings': 10,\n",
        "    'Public': 10,\n",
        "    'University': 8,\n",
        "    'IDC': 6,\n",
        "    'Department Store': 8,\n",
        "    'Hospital': 8,\n",
        "    'Commercial': 10,\n",
        "    'Apartment': 6,\n",
        "    'Research Institute': 10,\n",
        "    'Hotel': 10\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os3uee3mo_MO",
        "outputId": "85d400d4-ec67-4488-e2a6-8124fa16a916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building type = Hotel : XGB SMAPE = 4.3935\n",
            "Building type = Commercial : XGB SMAPE = 1.8392\n",
            "Building type = Hospital : XGB SMAPE = 2.0445\n",
            "Building type = University : XGB SMAPE = 2.1886\n",
            "Building type = Other Buildings : XGB SMAPE = 3.3996\n",
            "Building type = Apartment : XGB SMAPE = 2.7940\n",
            "Building type = Research Institute : XGB SMAPE = 3.0153\n",
            "Building type = Department Store : XGB SMAPE = 3.3539\n",
            "Building type = IDC : XGB SMAPE = 0.6311\n",
            "Building type = Public : XGB SMAPE = 3.6438\n",
            "Total SMAPE = 2.7712\n"
          ]
        }
      ],
      "source": [
        "# 건물 타입별 모델\n",
        "type_list = X[\"building_type\"].unique()\n",
        "\n",
        "answer_df = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df   = pd.DataFrame(index=X.index,       columns=[\"pred\"],   dtype=float)\n",
        "\n",
        "kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "for btype in type_list:\n",
        "    x  = X  [X['building_type'] == btype].copy()\n",
        "    y  = Y  [Y['building_type'] == btype]['power_consumption'].copy()\n",
        "    xt = test_X[test_X['building_type'] == btype].copy()\n",
        "\n",
        "    x  = pd.get_dummies(x,  columns=[\"building_number\"], drop_first=False)\n",
        "    xt = pd.get_dummies(xt, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "    xt = xt.reindex(columns=x.columns, fill_value=0)\n",
        "\n",
        "    drop_cols = [\"building_type\"]\n",
        "    x  = x .drop(columns=drop_cols)\n",
        "    xt = xt.drop(columns=drop_cols)\n",
        "\n",
        "    preds_valid = pd.Series(index=y.index, dtype=float)\n",
        "    preds_test  = []\n",
        "\n",
        "    x_values = x.values\n",
        "    y_values = y.values\n",
        "\n",
        "    fold_scores = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values), 1):\n",
        "        X_tr, X_va = x_values[tr_idx], x_values[va_idx]\n",
        "        y_tr, y_va = y_values[tr_idx], y_values[va_idx]\n",
        "\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            learning_rate     = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth         = max_depth_dict[btype],\n",
        "            subsample         = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective         = weighted_mse(3),\n",
        "            tree_method       = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        va_pred = np.exp(model.predict(X_va))\n",
        "        preds_valid.iloc[va_idx] = va_pred\n",
        "\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores.append(fold_smape)\n",
        "\n",
        "        preds_test.append(np.exp(model.predict(xt.values)))\n",
        "\n",
        "    pred_df.loc[preds_valid.index, \"pred\"] = preds_valid\n",
        "\n",
        "    answer_df.loc[xt.index, \"answer\"] = np.mean(preds_test, axis=0)\n",
        "\n",
        "    print(f\"Building type = {btype} : XGB SMAPE = {np.mean(fold_scores):.4f}\")\n",
        "\n",
        "total_smape = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE = {total_smape:.4f}\")\n",
        "\n",
        "pred_df.to_csv(f'{DATA_DIR}/pred_valid_nosummer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df.to_csv(f'{DATA_DIR}/answer_test_nosummer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09qKHg-No_MO",
        "outputId": "75d0c24e-2c8d-4f88-9a80-ce67ccb89fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building number = 1 : XGB SMAPE = 6.8060\n",
            "Building number = 2 : XGB SMAPE = 4.4365\n",
            "Building number = 3 : XGB SMAPE = 1.6559\n",
            "Building number = 4 : XGB SMAPE = 4.0734\n",
            "Building number = 5 : XGB SMAPE = 1.0035\n",
            "Building number = 6 : XGB SMAPE = 5.2791\n",
            "Building number = 7 : XGB SMAPE = 2.2819\n",
            "Building number = 8 : XGB SMAPE = 2.6724\n",
            "Building number = 9 : XGB SMAPE = 3.9303\n",
            "Building number = 10 : XGB SMAPE = 3.6799\n",
            "Building number = 11 : XGB SMAPE = 2.0568\n",
            "Building number = 12 : XGB SMAPE = 1.2134\n",
            "Building number = 13 : XGB SMAPE = 2.3945\n",
            "Building number = 14 : XGB SMAPE = 1.4533\n",
            "Building number = 15 : XGB SMAPE = 2.6818\n",
            "Building number = 16 : XGB SMAPE = 1.4676\n",
            "Building number = 17 : XGB SMAPE = 1.6931\n",
            "Building number = 18 : XGB SMAPE = 3.0366\n",
            "Building number = 19 : XGB SMAPE = 4.2689\n",
            "Building number = 20 : XGB SMAPE = 0.6946\n",
            "Building number = 21 : XGB SMAPE = 1.2818\n",
            "Building number = 22 : XGB SMAPE = 2.1128\n",
            "Building number = 23 : XGB SMAPE = 6.2833\n",
            "Building number = 24 : XGB SMAPE = 3.3303\n",
            "Building number = 25 : XGB SMAPE = 5.4824\n",
            "Building number = 26 : XGB SMAPE = 5.2366\n",
            "Building number = 27 : XGB SMAPE = 2.6283\n",
            "Building number = 28 : XGB SMAPE = 2.3692\n",
            "Building number = 29 : XGB SMAPE = 1.6524\n",
            "Building number = 30 : XGB SMAPE = 0.1887\n",
            "Building number = 31 : XGB SMAPE = 1.9698\n",
            "Building number = 32 : XGB SMAPE = 3.0345\n",
            "Building number = 33 : XGB SMAPE = 6.7231\n",
            "Building number = 34 : XGB SMAPE = 1.9049\n",
            "Building number = 35 : XGB SMAPE = 0.1586\n",
            "Building number = 36 : XGB SMAPE = 0.2918\n",
            "Building number = 37 : XGB SMAPE = 3.1106\n",
            "Building number = 38 : XGB SMAPE = 2.1024\n",
            "Building number = 39 : XGB SMAPE = 2.6009\n",
            "Building number = 40 : XGB SMAPE = 2.5051\n",
            "Building number = 41 : XGB SMAPE = 0.1811\n",
            "Building number = 42 : XGB SMAPE = 1.2577\n",
            "Building number = 43 : XGB SMAPE = 0.6118\n",
            "Building number = 44 : XGB SMAPE = 1.7286\n",
            "Building number = 45 : XGB SMAPE = 3.2012\n",
            "Building number = 46 : XGB SMAPE = 3.4290\n",
            "Building number = 47 : XGB SMAPE = 2.1542\n",
            "Building number = 48 : XGB SMAPE = 2.3975\n",
            "Building number = 49 : XGB SMAPE = 3.8719\n",
            "Building number = 50 : XGB SMAPE = 3.7652\n",
            "Building number = 51 : XGB SMAPE = 0.4153\n",
            "Building number = 52 : XGB SMAPE = 0.5448\n",
            "Building number = 53 : XGB SMAPE = 2.4417\n",
            "Building number = 54 : XGB SMAPE = 6.0703\n",
            "Building number = 55 : XGB SMAPE = 1.1000\n",
            "Building number = 56 : XGB SMAPE = 0.3990\n",
            "Building number = 57 : XGB SMAPE = 0.7066\n",
            "Building number = 58 : XGB SMAPE = 2.8629\n",
            "Building number = 59 : XGB SMAPE = 3.7169\n",
            "Building number = 60 : XGB SMAPE = 2.0422\n",
            "Building number = 61 : XGB SMAPE = 4.6820\n",
            "Building number = 62 : XGB SMAPE = 1.1556\n",
            "Building number = 63 : XGB SMAPE = 2.2811\n",
            "Building number = 64 : XGB SMAPE = 1.1247\n",
            "Building number = 65 : XGB SMAPE = 3.8176\n",
            "Building number = 66 : XGB SMAPE = 2.6715\n",
            "Building number = 67 : XGB SMAPE = 0.4643\n",
            "Building number = 68 : XGB SMAPE = 4.4912\n",
            "Building number = 69 : XGB SMAPE = 1.4569\n",
            "Building number = 70 : XGB SMAPE = 1.9016\n",
            "Building number = 71 : XGB SMAPE = 1.7461\n",
            "Building number = 72 : XGB SMAPE = 3.9292\n",
            "Building number = 73 : XGB SMAPE = 2.7155\n",
            "Building number = 74 : XGB SMAPE = 3.5072\n",
            "Building number = 75 : XGB SMAPE = 2.6404\n",
            "Building number = 76 : XGB SMAPE = 0.6557\n",
            "Building number = 77 : XGB SMAPE = 6.2132\n",
            "Building number = 78 : XGB SMAPE = 1.7836\n",
            "Building number = 79 : XGB SMAPE = 2.5257\n",
            "Building number = 80 : XGB SMAPE = 2.1377\n",
            "Building number = 81 : XGB SMAPE = 1.0225\n",
            "Building number = 82 : XGB SMAPE = 3.0812\n",
            "Building number = 83 : XGB SMAPE = 1.5055\n",
            "Building number = 84 : XGB SMAPE = 2.5451\n",
            "Building number = 85 : XGB SMAPE = 5.6367\n",
            "Building number = 86 : XGB SMAPE = 2.2634\n",
            "Building number = 87 : XGB SMAPE = 3.1238\n",
            "Building number = 88 : XGB SMAPE = 3.4702\n",
            "Building number = 89 : XGB SMAPE = 1.9197\n",
            "Building number = 90 : XGB SMAPE = 3.1050\n",
            "Building number = 91 : XGB SMAPE = 1.5314\n",
            "Building number = 92 : XGB SMAPE = 2.6975\n",
            "Building number = 93 : XGB SMAPE = 1.6848\n",
            "Building number = 94 : XGB SMAPE = 3.0550\n",
            "Building number = 95 : XGB SMAPE = 4.2051\n",
            "Building number = 96 : XGB SMAPE = 3.3889\n",
            "Building number = 97 : XGB SMAPE = 5.0825\n",
            "Building number = 98 : XGB SMAPE = 3.4553\n",
            "Building number = 99 : XGB SMAPE = 1.8892\n",
            "Building number = 100 : XGB SMAPE = 7.7656\n",
            "Total SMAPE (by Building) = 2.6906\n"
          ]
        }
      ],
      "source": [
        "# 건물별 모델\n",
        "\n",
        "Y = train[['building_number','power_consumption']]\n",
        "\n",
        "answer_df_by_building = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df_by_building = pd.DataFrame(index=X.index, columns=[\"pred\"], dtype=float)\n",
        "\n",
        "building_numbers = X[\"building_number\"].unique()\n",
        "\n",
        "for bnum in building_numbers:\n",
        "    x_building = X[X['building_number'] == bnum].copy()\n",
        "    y_building = Y[Y['building_number'] == bnum]['power_consumption'].copy()\n",
        "    xt_building = test_X[test_X['building_number'] == bnum].copy()\n",
        "\n",
        "    current_building_type = X[X['building_number'] == bnum]['building_type'].iloc[0]\n",
        "    current_max_depth = max_depth_dict.get(current_building_type, 10)\n",
        "\n",
        "    drop_cols_building = [\"building_type\", \"building_number\"]\n",
        "    x_building = x_building.drop(columns=drop_cols_building, errors='ignore')\n",
        "    xt_building = xt_building.drop(columns=drop_cols_building, errors='ignore')\n",
        "\n",
        "    xt_building = xt_building.reindex(columns=x_building.columns, fill_value=0)\n",
        "\n",
        "    preds_valid_building = pd.Series(index=y_building.index, dtype=float)\n",
        "    preds_test_building = []\n",
        "\n",
        "    x_values_building = x_building.values\n",
        "    y_values_building = y_building.values\n",
        "\n",
        "    fold_scores_building = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values_building), 1):\n",
        "        X_tr, X_va = x_values_building[tr_idx], x_values_building[va_idx]\n",
        "        y_tr, y_va = y_values_building[tr_idx], y_values_building[va_idx]\n",
        "\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "\n",
        "        model_building = XGBRegressor(\n",
        "            learning_rate     = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth         = current_max_depth,\n",
        "            subsample         = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective         = weighted_mse(3),\n",
        "            tree_method       = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "        model_building.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        va_pred = np.exp(model_building.predict(X_va))\n",
        "        preds_valid_building.iloc[va_idx] = va_pred\n",
        "\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores_building.append(fold_smape)\n",
        "\n",
        "        preds_test_building.append(np.exp(model_building.predict(xt_building.values)))\n",
        "\n",
        "    pred_df_by_building.loc[preds_valid_building.index, \"pred\"] = preds_valid_building\n",
        "    answer_df_by_building.loc[xt_building.index, \"answer\"] = np.mean(preds_test_building, axis=0)\n",
        "\n",
        "    print(f\"Building number = {bnum} : XGB SMAPE = {np.mean(fold_scores_building):.4f}\")\n",
        "\n",
        "total_smape_by_building = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df_by_building.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE (by Building) = {total_smape_by_building:.4f}\")\n",
        "\n",
        "pred_df_by_building.to_csv(f'{DATA_DIR}/pred_valid_by_building_nosummer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df_by_building.to_csv(f'{DATA_DIR}/answer_test_by_building_nosummer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG8TE2ujo_MP",
        "outputId": "147e755c-324e-4e19-af3a-d449c84bd9e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Model : XGB SMAPE = 2.7776\n",
            "Total SMAPE (Global) = 2.7776\n"
          ]
        }
      ],
      "source": [
        "# 전체 모델\n",
        "\n",
        "answer_df_global = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df_global = pd.DataFrame(index=X.index, columns=[\"pred\"], dtype=float)\n",
        "\n",
        "x_global = pd.get_dummies(X.copy(), columns=[\"building_type\"], drop_first=False)\n",
        "xt_global = pd.get_dummies(test_X.copy(), columns=[\"building_type\"], drop_first=False)\n",
        "\n",
        "x_global = pd.get_dummies(x_global, columns=[\"building_number\"], drop_first=False)\n",
        "xt_global = pd.get_dummies(xt_global, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "drop_cols_global = []\n",
        "\n",
        "x_global = x_global.drop(columns=drop_cols_global, errors='ignore')\n",
        "xt_global = xt_global.drop(columns=drop_cols_global, errors='ignore')\n",
        "\n",
        "xt_global = xt_global.reindex(columns=x_global.columns, fill_value=0)\n",
        "\n",
        "y_global = Y['power_consumption'].copy()\n",
        "\n",
        "preds_valid_global = pd.Series(index=y_global.index, dtype=float)\n",
        "preds_test_global = []\n",
        "\n",
        "x_values_global = x_global.values\n",
        "y_values_global = y_global.values\n",
        "\n",
        "fold_scores_global = []\n",
        "for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values_global), 1):\n",
        "    X_tr, X_va = x_values_global[tr_idx], x_values_global[va_idx]\n",
        "    y_tr, y_va = y_values_global[tr_idx], y_values_global[va_idx]\n",
        "\n",
        "    y_tr_log = np.log(y_tr)\n",
        "    y_va_log = np.log(y_va)\n",
        "\n",
        "    model_global = XGBRegressor(\n",
        "            learning_rate     = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth         = 10,\n",
        "            subsample         = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective         = weighted_mse(3),\n",
        "            tree_method       = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "    model_global.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "    va_pred = np.exp(model_global.predict(X_va))\n",
        "    preds_valid_global.iloc[va_idx] = va_pred\n",
        "\n",
        "    fold_smape = smape(y_va, va_pred)\n",
        "    fold_scores_global.append(fold_smape)\n",
        "\n",
        "    preds_test_global.append(np.exp(model_global.predict(xt_global.values)))\n",
        "\n",
        "pred_df_global.loc[preds_valid_global.index, \"pred\"] = preds_valid_global\n",
        "answer_df_global.loc[xt_global.index, \"answer\"] = np.mean(preds_test_global, axis=0)\n",
        "\n",
        "print(f\"Global Model : XGB SMAPE = {np.mean(fold_scores_global):.4f}\")\n",
        "\n",
        "total_smape_global = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df_global.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE (Global) = {total_smape_global:.4f}\")\n",
        "\n",
        "pred_df_global.to_csv(f'{DATA_DIR}/pred_valid_by_global_nosummer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df_global.to_csv(f'{DATA_DIR}/answer_test_by_global_nosummer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ensemble of no summer features across building-type, building-specific, and global models**"
      ],
      "metadata": {
        "id": "u3WzrxP7iaBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFdLTztuo_MP"
      },
      "outputs": [],
      "source": [
        "answer_df = pd.read_csv(f'{DATA_DIR}/answer_test_nosummer{RANDOM_SEED}.csv')\n",
        "answer_df_by_building = pd.read_csv(f'{DATA_DIR}/answer_test_by_building_nosummer{RANDOM_SEED}.csv')\n",
        "answer_df_global = pd.read_csv(f'{DATA_DIR}/answer_test_by_global_nosummer{RANDOM_SEED}.csv')\n",
        "\n",
        "final_ensemble_test_pred = (\n",
        "    answer_df.sort_index()[\"answer\"].values * 0.25 +\n",
        "    answer_df_by_building.sort_index()[\"answer\"].values * 0.25 +\n",
        "    answer_df_global.sort_index()[\"answer\"].values * 0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv8tWSsro_MP"
      },
      "outputs": [],
      "source": [
        "final_ensemble_test_pred_fixed = [max(0, x) for x in final_ensemble_test_pred]\n",
        "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
        "submission['answer'] = final_ensemble_test_pred_fixed\n",
        "submission.to_csv(f'{DATA_DIR}/5.16_nosummer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHK7-ls-JJql"
      },
      "source": [
        "# **No Summer Feature Cluster Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U9SULXBonPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b29f1e-db51-4527-b9a5-8222c0504e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster-wise building count:\n",
            "cluster\n",
            "0    12\n",
            "1     4\n",
            "2    47\n",
            "3     9\n",
            "4    28\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Total number of buildings: 100\n"
          ]
        }
      ],
      "source": [
        "train, test = Preprocessing(False, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRiv9M35JJqq"
      },
      "outputs": [],
      "source": [
        "X = train.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity',\n",
        "                'power_consumption','rainfall', 'sunshine', 'solar_radiation',\n",
        "                'hour','day','month','day_of_week','date_time', 'building_type'],axis =1 )\n",
        "\n",
        "Y = train[['cluster','power_consumption']]\n",
        "\n",
        "test_X = test.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity','rainfall',\n",
        "                   'hour','month','day_of_week','day','date_time'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmgdz8GKJJqq",
        "outputId": "2b7baa27-a97b-4169-d830-14c7a02dbb36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Cluster = 0 : XGB SMAPE = 2.2067\n",
            "Building Cluster = 1 : XGB SMAPE = 0.8337\n",
            "Building Cluster = 2 : XGB SMAPE = 3.2006\n",
            "Building Cluster = 3 : XGB SMAPE = 1.4139\n",
            "Building Cluster = 4 : XGB SMAPE = 3.1558\n",
            "Total SMAPE = 2.8129\n"
          ]
        }
      ],
      "source": [
        "cluster_list = sorted(train[\"cluster\"].unique())\n",
        "\n",
        "max_depth_dict_cluster = {\n",
        "    0: 10,\n",
        "    1: 8,\n",
        "    2: 10,\n",
        "    3: 8,\n",
        "    4: 10\n",
        "}\n",
        "\n",
        "answer_df_cluster = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df_cluster   = pd.DataFrame(index=X.index,         columns=[\"pred\"],    dtype=float)\n",
        "\n",
        "kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "for cluster_num in cluster_list:\n",
        "    x  = X[X['cluster'] == cluster_num].copy()\n",
        "    y  = Y[Y['cluster'] == cluster_num]['power_consumption'].copy()\n",
        "    xt = test_X[test_X['cluster'] == cluster_num].copy()\n",
        "\n",
        "    x  = pd.get_dummies(x,  columns=[\"building_number\"], drop_first=False)\n",
        "    xt = pd.get_dummies(xt, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "    xt = xt.reindex(columns=x.columns, fill_value=0)\n",
        "\n",
        "    drop_cols = [\"cluster\"]\n",
        "    x  = x.drop(columns=drop_cols)\n",
        "    xt = xt.drop(columns=drop_cols)\n",
        "\n",
        "    preds_valid = pd.Series(index=y.index, dtype=float)\n",
        "    preds_test  = []\n",
        "\n",
        "    x_values = x.values\n",
        "    y_values = y.values\n",
        "\n",
        "    fold_scores = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values), 1):\n",
        "        X_tr, X_va = x_values[tr_idx], x_values[va_idx]\n",
        "        y_tr, y_va = y_values[tr_idx], y_values[va_idx]\n",
        "\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            learning_rate      = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth          = max_depth_dict_cluster[cluster_num],\n",
        "            subsample          = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective          = weighted_mse(3),\n",
        "            tree_method        = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        va_pred = np.exp(model.predict(X_va))\n",
        "        preds_valid.iloc[va_idx] = va_pred\n",
        "\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores.append(fold_smape)\n",
        "\n",
        "        preds_test.append(np.exp(model.predict(xt.values)))\n",
        "\n",
        "    pred_df_cluster.loc[preds_valid.index, \"pred\"] = preds_valid\n",
        "    answer_df_cluster.loc[xt.index, \"answer\"] = np.mean(preds_test, axis=0)\n",
        "\n",
        "    print(f\"Building Cluster = {cluster_num} : XGB SMAPE = {np.mean(fold_scores):.4f}\")\n",
        "\n",
        "total_smape = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df_cluster.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE = {total_smape:.4f}\")\n",
        "\n",
        "pred_df_cluster.to_csv(f'{DATA_DIR}/pred_valid_by_cluster_nosummer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df_cluster.to_csv(f'{DATA_DIR}/answer_test_by_cluster_nosummer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM_vJbUFJJqr"
      },
      "outputs": [],
      "source": [
        "answer_df_cluster = pd.read_csv(f'{DATA_DIR}/answer_test_by_cluster_nosummer{RANDOM_SEED}.csv')\n",
        "final_ensemble_test_pred = answer_df_cluster.sort_index()[\"answer\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_T6YlKgJJqr"
      },
      "outputs": [],
      "source": [
        "final_ensemble_test_pred_fixed = [max(0, x) for x in final_ensemble_test_pred]\n",
        "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
        "submission['answer'] = final_ensemble_test_pred_fixed\n",
        "submission.to_csv(f'{DATA_DIR}/5.16_nosummer_cluster{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_31FzZPuE-z"
      },
      "source": [
        "# **Summer Feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md4BJSqen9CK"
      },
      "outputs": [],
      "source": [
        "train, test = Preprocessing(True, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahnFEQv9eA62"
      },
      "outputs": [],
      "source": [
        "X = train.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity',\n",
        "                'power_consumption','rainfall', 'sunshine', 'solar_radiation',\n",
        "                'hour','day','month','day_of_week','date_time'],axis =1 )\n",
        "\n",
        "Y = train[['building_type','power_consumption']]\n",
        "\n",
        "test_X = test.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity','rainfall',\n",
        "                   'hour','month','day_of_week','day','date_time'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0lHESEteA62"
      },
      "outputs": [],
      "source": [
        "type_list = []\n",
        "for value in train.building_type.values:\n",
        "    if value not in type_list:\n",
        "        type_list.append(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeoyEuFhaH8s"
      },
      "outputs": [],
      "source": [
        "max_depth_dict = {\n",
        "    'Other Buildings': 10,\n",
        "    'Public': 10,\n",
        "    'University': 8,\n",
        "    'IDC': 6,\n",
        "    'Department Store': 8,\n",
        "    'Hospital': 8,\n",
        "    'Commercial': 10,\n",
        "    'Apartment': 6,\n",
        "    'Research Institute': 10,\n",
        "    'Hotel': 10\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "550YeN--eA62",
        "outputId": "55f60b99-7aa6-4fea-8330-9f1f3f49961f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building type = Hotel : XGB SMAPE = 4.2469\n",
            "Building type = Commercial : XGB SMAPE = 1.8077\n",
            "Building type = Hospital : XGB SMAPE = 1.9830\n",
            "Building type = University : XGB SMAPE = 2.1372\n",
            "Building type = Other Buildings : XGB SMAPE = 3.3220\n",
            "Building type = Apartment : XGB SMAPE = 2.6941\n",
            "Building type = Research Institute : XGB SMAPE = 2.9108\n",
            "Building type = Department Store : XGB SMAPE = 3.2780\n",
            "Building type = IDC : XGB SMAPE = 0.6285\n",
            "Building type = Public : XGB SMAPE = 3.5128\n",
            "Total SMAPE = 2.6937\n"
          ]
        }
      ],
      "source": [
        "# 건물 타입별 모델\n",
        "\n",
        "type_list = X[\"building_type\"].unique()\n",
        "\n",
        "answer_df = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df   = pd.DataFrame(index=X.index,       columns=[\"pred\"],   dtype=float)\n",
        "\n",
        "kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "for btype in type_list:\n",
        "    x  = X  [X['building_type'] == btype].copy()\n",
        "    y  = Y  [Y['building_type'] == btype]['power_consumption'].copy()\n",
        "    xt = test_X[test_X['building_type'] == btype].copy()\n",
        "\n",
        "    x  = pd.get_dummies(x,  columns=[\"building_number\"], drop_first=False)\n",
        "    xt = pd.get_dummies(xt, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "    xt = xt.reindex(columns=x.columns, fill_value=0)\n",
        "\n",
        "    drop_cols = [\"building_type\"]\n",
        "    x  = x .drop(columns=drop_cols)\n",
        "    xt = xt.drop(columns=drop_cols)\n",
        "\n",
        "    preds_valid = pd.Series(index=y.index, dtype=float)\n",
        "    preds_test  = []\n",
        "\n",
        "    x_values = x.values\n",
        "    y_values = y.values\n",
        "\n",
        "    fold_scores = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values), 1):\n",
        "        X_tr, X_va = x_values[tr_idx], x_values[va_idx]\n",
        "        y_tr, y_va = y_values[tr_idx], y_values[va_idx]\n",
        "\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            learning_rate     = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth         = max_depth_dict[btype],\n",
        "            subsample         = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective         = weighted_mse(3),\n",
        "            tree_method       = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        va_pred = np.exp(model.predict(X_va))\n",
        "        preds_valid.iloc[va_idx] = va_pred\n",
        "\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores.append(fold_smape)\n",
        "\n",
        "        preds_test.append(np.exp(model.predict(xt.values)))\n",
        "\n",
        "    pred_df.loc[preds_valid.index, \"pred\"] = preds_valid\n",
        "\n",
        "    answer_df.loc[xt.index, \"answer\"] = np.mean(preds_test, axis=0)\n",
        "\n",
        "    print(f\"Building type = {btype} : XGB SMAPE = {np.mean(fold_scores):.4f}\")\n",
        "\n",
        "total_smape = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE = {total_smape:.4f}\")\n",
        "\n",
        "pred_df.to_csv(f'{DATA_DIR}/pred_valid_summer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df.to_csv(f'{DATA_DIR}/answer_test_summer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FNy8LupeA63",
        "outputId": "44f39137-c867-4328-a038-65522e9bcd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building number = 1 : XGB SMAPE = 6.5859\n",
            "Building number = 2 : XGB SMAPE = 4.3622\n",
            "Building number = 3 : XGB SMAPE = 1.5629\n",
            "Building number = 4 : XGB SMAPE = 3.9032\n",
            "Building number = 5 : XGB SMAPE = 0.9665\n",
            "Building number = 6 : XGB SMAPE = 5.0152\n",
            "Building number = 7 : XGB SMAPE = 2.2129\n",
            "Building number = 8 : XGB SMAPE = 2.5517\n",
            "Building number = 9 : XGB SMAPE = 3.6938\n",
            "Building number = 10 : XGB SMAPE = 3.3381\n",
            "Building number = 11 : XGB SMAPE = 2.0084\n",
            "Building number = 12 : XGB SMAPE = 1.1604\n",
            "Building number = 13 : XGB SMAPE = 2.3091\n",
            "Building number = 14 : XGB SMAPE = 1.3709\n",
            "Building number = 15 : XGB SMAPE = 2.6360\n",
            "Building number = 16 : XGB SMAPE = 1.4285\n",
            "Building number = 17 : XGB SMAPE = 1.6203\n",
            "Building number = 18 : XGB SMAPE = 3.0421\n",
            "Building number = 19 : XGB SMAPE = 4.1602\n",
            "Building number = 20 : XGB SMAPE = 0.6824\n",
            "Building number = 21 : XGB SMAPE = 1.2103\n",
            "Building number = 22 : XGB SMAPE = 2.0327\n",
            "Building number = 23 : XGB SMAPE = 5.8610\n",
            "Building number = 24 : XGB SMAPE = 3.1796\n",
            "Building number = 25 : XGB SMAPE = 5.1134\n",
            "Building number = 26 : XGB SMAPE = 4.9583\n",
            "Building number = 27 : XGB SMAPE = 2.5798\n",
            "Building number = 28 : XGB SMAPE = 2.2645\n",
            "Building number = 29 : XGB SMAPE = 1.6168\n",
            "Building number = 30 : XGB SMAPE = 0.1740\n",
            "Building number = 31 : XGB SMAPE = 1.9399\n",
            "Building number = 32 : XGB SMAPE = 2.9535\n",
            "Building number = 33 : XGB SMAPE = 6.5546\n",
            "Building number = 34 : XGB SMAPE = 1.8623\n",
            "Building number = 35 : XGB SMAPE = 0.1522\n",
            "Building number = 36 : XGB SMAPE = 0.2763\n",
            "Building number = 37 : XGB SMAPE = 3.0588\n",
            "Building number = 38 : XGB SMAPE = 2.0809\n",
            "Building number = 39 : XGB SMAPE = 2.4408\n",
            "Building number = 40 : XGB SMAPE = 2.4451\n",
            "Building number = 41 : XGB SMAPE = 0.1699\n",
            "Building number = 42 : XGB SMAPE = 1.2170\n",
            "Building number = 43 : XGB SMAPE = 0.5791\n",
            "Building number = 44 : XGB SMAPE = 1.6551\n",
            "Building number = 45 : XGB SMAPE = 3.0889\n",
            "Building number = 46 : XGB SMAPE = 3.2850\n",
            "Building number = 47 : XGB SMAPE = 2.1377\n",
            "Building number = 48 : XGB SMAPE = 2.2792\n",
            "Building number = 49 : XGB SMAPE = 3.7386\n",
            "Building number = 50 : XGB SMAPE = 3.6120\n",
            "Building number = 51 : XGB SMAPE = 0.4027\n",
            "Building number = 52 : XGB SMAPE = 0.5022\n",
            "Building number = 53 : XGB SMAPE = 2.2408\n",
            "Building number = 54 : XGB SMAPE = 5.8251\n",
            "Building number = 55 : XGB SMAPE = 1.0632\n",
            "Building number = 56 : XGB SMAPE = 0.3885\n",
            "Building number = 57 : XGB SMAPE = 0.6472\n",
            "Building number = 58 : XGB SMAPE = 2.8233\n",
            "Building number = 59 : XGB SMAPE = 3.4781\n",
            "Building number = 60 : XGB SMAPE = 2.0309\n",
            "Building number = 61 : XGB SMAPE = 4.5030\n",
            "Building number = 62 : XGB SMAPE = 1.1180\n",
            "Building number = 63 : XGB SMAPE = 2.2363\n",
            "Building number = 64 : XGB SMAPE = 1.0632\n",
            "Building number = 65 : XGB SMAPE = 3.6353\n",
            "Building number = 66 : XGB SMAPE = 2.5847\n",
            "Building number = 67 : XGB SMAPE = 0.4460\n",
            "Building number = 68 : XGB SMAPE = 4.3294\n",
            "Building number = 69 : XGB SMAPE = 1.4119\n",
            "Building number = 70 : XGB SMAPE = 1.8475\n",
            "Building number = 71 : XGB SMAPE = 1.6705\n",
            "Building number = 72 : XGB SMAPE = 3.7591\n",
            "Building number = 73 : XGB SMAPE = 2.5616\n",
            "Building number = 74 : XGB SMAPE = 3.3224\n",
            "Building number = 75 : XGB SMAPE = 2.6348\n",
            "Building number = 76 : XGB SMAPE = 0.6175\n",
            "Building number = 77 : XGB SMAPE = 5.8545\n",
            "Building number = 78 : XGB SMAPE = 1.7434\n",
            "Building number = 79 : XGB SMAPE = 2.4790\n",
            "Building number = 80 : XGB SMAPE = 1.9535\n",
            "Building number = 81 : XGB SMAPE = 0.9208\n",
            "Building number = 82 : XGB SMAPE = 2.9989\n",
            "Building number = 83 : XGB SMAPE = 1.4003\n",
            "Building number = 84 : XGB SMAPE = 2.5003\n",
            "Building number = 85 : XGB SMAPE = 5.7468\n",
            "Building number = 86 : XGB SMAPE = 2.2444\n",
            "Building number = 87 : XGB SMAPE = 3.0135\n",
            "Building number = 88 : XGB SMAPE = 3.3106\n",
            "Building number = 89 : XGB SMAPE = 1.8502\n",
            "Building number = 90 : XGB SMAPE = 2.9121\n",
            "Building number = 91 : XGB SMAPE = 1.4723\n",
            "Building number = 92 : XGB SMAPE = 2.6186\n",
            "Building number = 93 : XGB SMAPE = 1.6158\n",
            "Building number = 94 : XGB SMAPE = 2.8979\n",
            "Building number = 95 : XGB SMAPE = 3.9075\n",
            "Building number = 96 : XGB SMAPE = 3.2944\n",
            "Building number = 97 : XGB SMAPE = 5.1155\n",
            "Building number = 98 : XGB SMAPE = 3.3025\n",
            "Building number = 99 : XGB SMAPE = 1.8261\n",
            "Building number = 100 : XGB SMAPE = 7.3891\n",
            "Total SMAPE (by Building) = 2.5874\n"
          ]
        }
      ],
      "source": [
        "# 건물별 모델\n",
        "\n",
        "Y = train[['building_number','power_consumption']]\n",
        "\n",
        "answer_df_by_building = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df_by_building = pd.DataFrame(index=X.index, columns=[\"pred\"], dtype=float)\n",
        "\n",
        "building_numbers = X[\"building_number\"].unique()\n",
        "\n",
        "for bnum in building_numbers:\n",
        "    x_building = X[X['building_number'] == bnum].copy()\n",
        "    y_building = Y[Y['building_number'] == bnum]['power_consumption'].copy()\n",
        "    xt_building = test_X[test_X['building_number'] == bnum].copy()\n",
        "\n",
        "    current_building_type = X[X['building_number'] == bnum]['building_type'].iloc[0]\n",
        "    current_max_depth = max_depth_dict.get(current_building_type, 10)\n",
        "\n",
        "    drop_cols_building = [\"building_type\", \"building_number\"]\n",
        "    x_building = x_building.drop(columns=drop_cols_building, errors='ignore')\n",
        "    xt_building = xt_building.drop(columns=drop_cols_building, errors='ignore')\n",
        "\n",
        "    xt_building = xt_building.reindex(columns=x_building.columns, fill_value=0)\n",
        "\n",
        "    preds_valid_building = pd.Series(index=y_building.index, dtype=float)\n",
        "    preds_test_building = []\n",
        "\n",
        "    x_values_building = x_building.values\n",
        "    y_values_building = y_building.values\n",
        "\n",
        "    fold_scores_building = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values_building), 1):\n",
        "        X_tr, X_va = x_values_building[tr_idx], x_values_building[va_idx]\n",
        "        y_tr, y_va = y_values_building[tr_idx], y_values_building[va_idx]\n",
        "\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "\n",
        "        model_building = XGBRegressor(\n",
        "            learning_rate     = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth         = current_max_depth,\n",
        "            subsample         = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective         = weighted_mse(3),\n",
        "            tree_method       = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "        model_building.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        va_pred = np.exp(model_building.predict(X_va))\n",
        "        preds_valid_building.iloc[va_idx] = va_pred\n",
        "\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores_building.append(fold_smape)\n",
        "\n",
        "        preds_test_building.append(np.exp(model_building.predict(xt_building.values)))\n",
        "\n",
        "    pred_df_by_building.loc[preds_valid_building.index, \"pred\"] = preds_valid_building\n",
        "    answer_df_by_building.loc[xt_building.index, \"answer\"] = np.mean(preds_test_building, axis=0)\n",
        "\n",
        "    print(f\"Building number = {bnum} : XGB SMAPE = {np.mean(fold_scores_building):.4f}\")\n",
        "\n",
        "total_smape_by_building = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df_by_building.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE (by Building) = {total_smape_by_building:.4f}\")\n",
        "\n",
        "pred_df_by_building.to_csv(f'{DATA_DIR}/pred_valid_by_building_summer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df_by_building.to_csv(f'{DATA_DIR}/answer_test_by_building_summer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfZMQz-HeA63",
        "outputId": "09d530a9-864f-4be4-dd10-a39a866cab08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global Model : XGB SMAPE = 2.7091\n",
            "Total SMAPE (Global) = 2.7091\n"
          ]
        }
      ],
      "source": [
        "# 전체 모델\n",
        "\n",
        "answer_df_global = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df_global = pd.DataFrame(index=X.index, columns=[\"pred\"], dtype=float)\n",
        "\n",
        "x_global = pd.get_dummies(X.copy(), columns=[\"building_type\"], drop_first=False)\n",
        "xt_global = pd.get_dummies(test_X.copy(), columns=[\"building_type\"], drop_first=False)\n",
        "\n",
        "x_global = pd.get_dummies(x_global, columns=[\"building_number\"], drop_first=False)\n",
        "xt_global = pd.get_dummies(xt_global, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "drop_cols_global = []\n",
        "\n",
        "x_global = x_global.drop(columns=drop_cols_global, errors='ignore')\n",
        "xt_global = xt_global.drop(columns=drop_cols_global, errors='ignore')\n",
        "\n",
        "xt_global = xt_global.reindex(columns=x_global.columns, fill_value=0)\n",
        "\n",
        "y_global = Y['power_consumption'].copy()\n",
        "\n",
        "preds_valid_global = pd.Series(index=y_global.index, dtype=float)\n",
        "preds_test_global = []\n",
        "\n",
        "x_values_global = x_global.values\n",
        "y_values_global = y_global.values\n",
        "\n",
        "fold_scores_global = []\n",
        "for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values_global), 1):\n",
        "    X_tr, X_va = x_values_global[tr_idx], x_values_global[va_idx]\n",
        "    y_tr, y_va = y_values_global[tr_idx], y_values_global[va_idx]\n",
        "\n",
        "    y_tr_log = np.log(y_tr)\n",
        "    y_va_log = np.log(y_va)\n",
        "\n",
        "    model_global = XGBRegressor(\n",
        "            learning_rate     = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth         = 10,\n",
        "            subsample         = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective         = weighted_mse(3),\n",
        "            tree_method       = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "    model_global.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "    va_pred = np.exp(model_global.predict(X_va))\n",
        "    preds_valid_global.iloc[va_idx] = va_pred\n",
        "\n",
        "    fold_smape = smape(y_va, va_pred)\n",
        "    fold_scores_global.append(fold_smape)\n",
        "\n",
        "    preds_test_global.append(np.exp(model_global.predict(xt_global.values)))\n",
        "\n",
        "pred_df_global.loc[preds_valid_global.index, \"pred\"] = preds_valid_global\n",
        "answer_df_global.loc[xt_global.index, \"answer\"] = np.mean(preds_test_global, axis=0)\n",
        "\n",
        "print(f\"Global Model : XGB SMAPE = {np.mean(fold_scores_global):.4f}\")\n",
        "\n",
        "total_smape_global = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df_global.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE (Global) = {total_smape_global:.4f}\")\n",
        "\n",
        "pred_df_global.to_csv(f'{DATA_DIR}/pred_valid_by_global_summer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df_global.to_csv(f'{DATA_DIR}/answer_test_by_global_summer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ensemble of summer features across building-type, building-specific, and global models**"
      ],
      "metadata": {
        "id": "IpWeezj6iA-g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NKWaQDxeA64"
      },
      "outputs": [],
      "source": [
        "answer_df = pd.read_csv(f'{DATA_DIR}/answer_test_summer{RANDOM_SEED}.csv')\n",
        "answer_df_by_building = pd.read_csv(f'{DATA_DIR}/answer_test_by_building_summer{RANDOM_SEED}.csv')\n",
        "answer_df_global = pd.read_csv(f'{DATA_DIR}/answer_test_by_global_summer{RANDOM_SEED}.csv')\n",
        "\n",
        "final_ensemble_test_pred = (\n",
        "    answer_df.sort_index()[\"answer\"].values * 0.2 +\n",
        "    answer_df_by_building.sort_index()[\"answer\"].values * 0.3 +\n",
        "    answer_df_global.sort_index()[\"answer\"].values * 0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPV-g2kleA64"
      },
      "outputs": [],
      "source": [
        "final_ensemble_test_pred_fixed = [max(0, x) for x in final_ensemble_test_pred]\n",
        "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
        "submission['answer'] = final_ensemble_test_pred_fixed\n",
        "submission.to_csv(f'{DATA_DIR}/5.16_summer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjSdeOMphEsu"
      },
      "source": [
        "# **Summer Cluster Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJe1qxFHnk6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca69d60c-f4b8-4bb9-cb95-a17414e0de47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster-wise building count:\n",
            "cluster\n",
            "0    12\n",
            "1     4\n",
            "2    47\n",
            "3     9\n",
            "4    28\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Total number of buildings: 100\n"
          ]
        }
      ],
      "source": [
        "train, test = Preprocessing(True, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cqJYieUhEsw"
      },
      "outputs": [],
      "source": [
        "X = train.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity',\n",
        "                    'power_consumption','rainfall', 'sunshine', 'solar_radiation',\n",
        "                    'hour','day','month','day_of_week','date_time', 'building_type'],axis =1 )\n",
        "\n",
        "Y = train[['cluster','power_consumption']]\n",
        "\n",
        "test_X = test.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity','rainfall',\n",
        "                      'hour','month','day_of_week','day','date_time'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ISwQ_MhEsx",
        "outputId": "3faab7b6-f794-4dd0-e9e3-cca91e74aaf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Cluster = 0 : XGB SMAPE = 2.1547\n",
            "Building Cluster = 1 : XGB SMAPE = 0.8068\n",
            "Building Cluster = 2 : XGB SMAPE = 3.0776\n",
            "Building Cluster = 3 : XGB SMAPE = 1.3513\n",
            "Building Cluster = 4 : XGB SMAPE = 3.0664\n",
            "Total SMAPE = 2.7171\n"
          ]
        }
      ],
      "source": [
        "cluster_list = sorted(train[\"cluster\"].unique())\n",
        "\n",
        "max_depth_dict_cluster = {\n",
        "    0: 10,\n",
        "    1: 8,\n",
        "    2: 10,\n",
        "    3: 8,\n",
        "    4: 10\n",
        "}\n",
        "\n",
        "answer_df_cluster = pd.DataFrame(index=test_X.index, columns=[\"answer\"], dtype=float)\n",
        "pred_df_cluster   = pd.DataFrame(index=X.index,         columns=[\"pred\"],    dtype=float)\n",
        "\n",
        "kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
        "\n",
        "for cluster_num in cluster_list:\n",
        "    x  = X[X['cluster'] == cluster_num].copy()\n",
        "    y  = Y[Y['cluster'] == cluster_num]['power_consumption'].copy()\n",
        "    xt = test_X[test_X['cluster'] == cluster_num].copy()\n",
        "\n",
        "    x  = pd.get_dummies(x,  columns=[\"building_number\"], drop_first=False)\n",
        "    xt = pd.get_dummies(xt, columns=[\"building_number\"], drop_first=False)\n",
        "\n",
        "    xt = xt.reindex(columns=x.columns, fill_value=0)\n",
        "\n",
        "    drop_cols = [\"cluster\"]\n",
        "    x  = x.drop(columns=drop_cols)\n",
        "    xt = xt.drop(columns=drop_cols)\n",
        "\n",
        "    preds_valid = pd.Series(index=y.index, dtype=float)\n",
        "    preds_test  = []\n",
        "\n",
        "    x_values = x.values\n",
        "    y_values = y.values\n",
        "\n",
        "    fold_scores = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(kf.split(x_values), 1):\n",
        "        X_tr, X_va = x_values[tr_idx], x_values[va_idx]\n",
        "        y_tr, y_va = y_values[tr_idx], y_values[va_idx]\n",
        "\n",
        "        y_tr_log = np.log(y_tr)\n",
        "        y_va_log = np.log(y_va)\n",
        "\n",
        "        model = XGBRegressor(\n",
        "            learning_rate      = 0.05,\n",
        "            n_estimators      = 5000,\n",
        "            max_depth          = max_depth_dict_cluster[cluster_num],\n",
        "            subsample          = 0.7,\n",
        "            colsample_bytree  = 0.5,\n",
        "            min_child_weight  = 3,\n",
        "            random_state      = RANDOM_SEED,\n",
        "            objective          = weighted_mse(3),\n",
        "            tree_method        = \"gpu_hist\",\n",
        "            gpu_id            = 0,\n",
        "            early_stopping_rounds = 100,\n",
        "        )\n",
        "\n",
        "        model.fit(\n",
        "            X_tr, y_tr_log,\n",
        "            eval_set=[(X_va, y_va_log)],\n",
        "            eval_metric=custom_smape,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "        va_pred = np.exp(model.predict(X_va))\n",
        "        preds_valid.iloc[va_idx] = va_pred\n",
        "\n",
        "        fold_smape = smape(y_va, va_pred)\n",
        "        fold_scores.append(fold_smape)\n",
        "\n",
        "        preds_test.append(np.exp(model.predict(xt.values)))\n",
        "\n",
        "    pred_df_cluster.loc[preds_valid.index, \"pred\"] = preds_valid\n",
        "    answer_df_cluster.loc[xt.index, \"answer\"] = np.mean(preds_test, axis=0)\n",
        "\n",
        "    print(f\"Building Cluster = {cluster_num} : XGB SMAPE = {np.mean(fold_scores):.4f}\")\n",
        "\n",
        "total_smape = smape(\n",
        "    Y.sort_index()[\"power_consumption\"].values,\n",
        "    pred_df_cluster.sort_index()[\"pred\"].values\n",
        ")\n",
        "print(f\"Total SMAPE = {total_smape:.4f}\")\n",
        "\n",
        "pred_df_cluster.to_csv(f'{DATA_DIR}/pred_valid_by_cluster_summer{RANDOM_SEED}.csv', index=False)\n",
        "answer_df_cluster.to_csv(f'{DATA_DIR}/answer_test_by_cluster_summer{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KFVv0L1hEsx"
      },
      "outputs": [],
      "source": [
        "answer_df_cluster = pd.read_csv(f'{DATA_DIR}/answer_test_by_cluster_summer{RANDOM_SEED}.csv')\n",
        "final_ensemble_test_pred = answer_df_cluster.sort_index()[\"answer\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKUT0g3ahEsx"
      },
      "outputs": [],
      "source": [
        "final_ensemble_test_pred_fixed = [max(0, x) for x in final_ensemble_test_pred]\n",
        "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
        "submission['answer'] = final_ensemble_test_pred_fixed\n",
        "submission.to_csv(f'{DATA_DIR}/5.16_summer_cluster{RANDOM_SEED}.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YYdSO5wtfIZ"
      },
      "source": [
        "# **Seed Ensemble**\n",
        "## The following steps must be executed after repeating the previous stages with seeds set to 42, 8, 15, 2025, and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR2HaD33yE_n"
      },
      "outputs": [],
      "source": [
        "summer_paths = [\n",
        "    f'{DATA_DIR}/5.16_summer42.csv',\n",
        "    f'{DATA_DIR}/5.16_summer8.csv',\n",
        "    f'{DATA_DIR}/5.16_summer15.csv',\n",
        "    f'{DATA_DIR}/5.16_summer2025.csv',\n",
        "    f'{DATA_DIR}/5.16_summer1.csv'\n",
        "]\n",
        "\n",
        "nosummer_paths = [\n",
        "    f'{DATA_DIR}/5.16_nosummer42.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer8.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer15.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer2025.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer1.csv'\n",
        "]\n",
        "\n",
        "summer_cluster_paths = [\n",
        "    f'{DATA_DIR}/5.16_summer_cluster42.csv',\n",
        "    f'{DATA_DIR}/5.16_summer_cluster8.csv',\n",
        "    f'{DATA_DIR}/5.16_summer_cluster15.csv',\n",
        "    f'{DATA_DIR}/5.16_summer_cluster2025.csv',\n",
        "    f'{DATA_DIR}/5.16_summer_cluster1.csv'\n",
        "]\n",
        "\n",
        "nosummer_cluster_paths = [\n",
        "    f'{DATA_DIR}/5.16_nosummer_cluster42.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer_cluster8.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer_cluster15.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer_cluster2025.csv',\n",
        "    f'{DATA_DIR}/5.16_nosummer_cluster1.csv'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B2psVFwyE_n"
      },
      "outputs": [],
      "source": [
        "def split_num_date_time(df):\n",
        "    df[['building_num', 'date_time']] = df['num_date_time'].str.split('_', n=1, expand=True)\n",
        "    df['building_num'] = df['building_num'].astype(int)\n",
        "    return df\n",
        "\n",
        "def merge_and_average(file_paths):\n",
        "    df_merged = pd.read_csv(file_paths[0])\n",
        "    for i in range(1, len(file_paths)):\n",
        "        df_temp = pd.read_csv(file_paths[i])\n",
        "        df_merged = pd.merge(df_merged, df_temp, on='num_date_time', suffixes=('', f'_{i}'))\n",
        "    answer_cols = [col for col in df_merged.columns if 'answer' in col]\n",
        "    df_merged['answer_avg'] = df_merged[answer_cols].mean(axis=1)\n",
        "    return df_merged[['num_date_time', 'answer_avg']].rename(columns={'answer_avg': 'answer'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoK9Ma0NyE_o"
      },
      "outputs": [],
      "source": [
        "df_summer_avg = merge_and_average(summer_paths)\n",
        "df_nosummer_avg = merge_and_average(nosummer_paths)\n",
        "\n",
        "df_cluster_avg = merge_and_average(summer_cluster_paths)\n",
        "df_nosummer_cluster_avg = merge_and_average(nosummer_cluster_paths)\n",
        "\n",
        "df_summer_avg = df_summer_avg.sort_values('num_date_time').reset_index(drop=True)\n",
        "df_nosummer_avg = df_nosummer_avg.sort_values('num_date_time').reset_index(drop=True)\n",
        "df_cluster_avg = df_cluster_avg.sort_values('num_date_time').reset_index(drop=True)\n",
        "df_nosummer_cluster_avg = df_nosummer_cluster_avg.sort_values('num_date_time').reset_index(drop=True)\n",
        "\n",
        "ensemble_answer = (\n",
        "    (df_summer_avg['answer'] * 0.8 + df_nosummer_avg['answer'] * 0.2) * 0.8 +\n",
        "    (df_cluster_avg['answer'] * 0.7 + df_nosummer_cluster_avg['answer'] * 0.3) * 0.2\n",
        ")\n",
        "\n",
        "df_ensemble = pd.DataFrame({\n",
        "    'num_date_time': df_summer_avg['num_date_time'],\n",
        "    'answer': ensemble_answer\n",
        "})\n",
        "\n",
        "df_ensemble = split_num_date_time(df_ensemble)\n",
        "df_ensemble = df_ensemble.sort_values(by=['building_num', 'date_time']).reset_index(drop=True)\n",
        "df_ensemble = df_ensemble.drop(columns=['building_num', 'date_time'])\n",
        "\n",
        "df_ensemble.to_csv(f'{DATA_DIR}/all_ensemble.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSCL3av7pYQy"
      },
      "source": [
        "# **Post-processing (holiday adjustment)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgMG8mopyE_p"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(f'{DATA_DIR}/train.csv', encoding='utf-8-sig')\n",
        "building_info = pd.read_csv(f'{DATA_DIR}/building_info.csv', encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH-rWw7zyE_p"
      },
      "outputs": [],
      "source": [
        "train = train.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '일시': 'date_time',\n",
        "    '기온(°C)': 'temperature',\n",
        "    '강수량(mm)': 'rainfall',\n",
        "    '풍속(m/s)': 'windspeed',\n",
        "    '습도(%)': 'humidity',\n",
        "    '일조(hr)': 'sunshine',\n",
        "    '일사(MJ/m2)': 'solar_radiation',\n",
        "    '전력소비량(kWh)': 'power_consumption'\n",
        "})\n",
        "train.drop('num_date_time', axis = 1, inplace=True)\n",
        "\n",
        "building_info = building_info.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '건물유형': 'building_type',\n",
        "    '연면적(m2)': 'total_area',\n",
        "    '냉방면적(m2)': 'cooling_area',\n",
        "    '태양광용량(kW)': 'solar_power_capacity',\n",
        "    'ESS저장용량(kWh)': 'ess_capacity',\n",
        "    'PCS용량(kW)': 'pcs_capacity'\n",
        "})\n",
        "\n",
        "translation_dict = {\n",
        "    '건물기타': 'Other Buildings', '공공': 'Public', '학교': 'University',\n",
        "    '백화점': 'Department Store', '병원': 'Hospital', '상용': 'Commercial',\n",
        "    '아파트': 'Apartment', '연구소': 'Research Institute',\n",
        "    'IDC(전화국)': 'IDC', '호텔': 'Hotel'\n",
        "}\n",
        "building_info['building_type'] = building_info['building_type'].replace(translation_dict)\n",
        "\n",
        "train = pd.merge(train, building_info, on='building_number', how='left')\n",
        "train['date_time'] = pd.to_datetime(train['date_time'], format='%Y%m%d %H')\n",
        "train['hour'] = train['date_time'].dt.hour\n",
        "train['day'] = train['date_time'].dt.day\n",
        "train['month'] = train['date_time'].dt.month\n",
        "\n",
        "outlier_idx = train.index[train['power_consumption'] == 0].tolist()\n",
        "train.drop(index=outlier_idx, inplace=True)\n",
        "\n",
        "submission_file_path = f'{DATA_DIR}/all_ensemble.csv'\n",
        "submit = pd.read_csv(submission_file_path)\n",
        "\n",
        "test_raw = pd.read_csv(f'{DATA_DIR}/test.csv', encoding='utf-8-sig')\n",
        "test_raw = test_raw.rename(columns={\n",
        "    '건물번호': 'building_number',\n",
        "    '일시': 'date_time'\n",
        "})\n",
        "test_raw['date_time'] = pd.to_datetime(test_raw['date_time'], format='%Y%m%d %H')\n",
        "test_raw['hour'] = test_raw['date_time'].dt.hour\n",
        "test_raw['day'] = test_raw['date_time'].dt.day\n",
        "test_raw['month'] = test_raw['date_time'].dt.month\n",
        "\n",
        "submit = submit.merge(test_raw[['building_number', 'date_time', 'hour', 'day', 'month']],\n",
        "                      left_index=True, right_index=True, how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0f_HeBryE_q"
      },
      "outputs": [],
      "source": [
        "replacement_rules = {\n",
        "    29: {'target_date': {'month': 8, 'day': 25}, 'source_dates': [{'month': 6, 'days': [23]}, {'month': 7, 'days': [28]}]},\n",
        "    27: {'target_date': {'month': 8, 'day': 25}, 'source_dates': [{'month': 6, 'days': [9, 23]}, {'month': 7, 'days': [14, 28]}, {'month': 8, 'days': [11]}]},\n",
        "    32: {'target_date': {'month': 8, 'day': 26}, 'source_dates': [{'month': 6, 'days': [10, 24]}, {'month': 7, 'days': [8, 22]}, {'month': 8, 'days': [12]}]},\n",
        "    40: {'target_date': {'month': 8, 'day': 25}, 'source_dates': [{'month': 6, 'days': [9, 23]}, {'month': 7, 'days': [14, 28]}, {'month': 8, 'days': [11]}]},\n",
        "    59: {'target_date': {'month': 8, 'day': 25}, 'source_dates': [{'month': 6, 'days': [9, 23]}, {'month': 7, 'days': [14, 28]}, {'month': 8, 'days': [11]}]},\n",
        "    63: {'target_date': {'month': 8, 'day': 25}, 'source_dates': [{'month': 6, 'days': [9, 23]}, {'month': 7, 'days': [14, 28]}, {'month': 8, 'days': [11]}]}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f2UEptcyE_r"
      },
      "outputs": [],
      "source": [
        "for building_num, rules in replacement_rules.items():\n",
        "    target_month = rules['target_date']['month']\n",
        "    target_day = rules['target_date']['day']\n",
        "    source_dates = rules['source_dates']\n",
        "\n",
        "    for hour in range(24):\n",
        "        target_indices = submit[(submit['building_number'] == building_num) &\n",
        "                                (submit['month'] == target_month) &\n",
        "                                (submit['day'] == target_day) &\n",
        "                                (submit['hour'] == hour)].index\n",
        "\n",
        "        if not target_indices.empty:\n",
        "            source_data_filter = (train['building_number'] == building_num) & (train['hour'] == hour)\n",
        "\n",
        "            month_day_conditions = []\n",
        "            for src_date_info in source_dates:\n",
        "                month_day_conditions.append(\n",
        "                    (train['month'] == src_date_info['month']) &\n",
        "                    (train['day'].isin(src_date_info['days']))\n",
        "                )\n",
        "\n",
        "            if building_num == 29:\n",
        "                final_source_filter = source_data_filter & (month_day_conditions[0] | month_day_conditions[1])\n",
        "            else:\n",
        "                final_source_filter = source_data_filter & (month_day_conditions[0] | month_day_conditions[1] | month_day_conditions[2])\n",
        "\n",
        "            values = train[final_source_filter]['power_consumption'].values\n",
        "\n",
        "            if len(values) > 2:\n",
        "                trimmed_mean = (values.sum() - values.max() - values.min()) / (len(values) - 2)\n",
        "            elif len(values) == 2:\n",
        "                trimmed_mean = values.mean()\n",
        "            elif len(values) == 1:\n",
        "                trimmed_mean = values[0]\n",
        "            else:\n",
        "                trimmed_mean = np.nan\n",
        "\n",
        "            submit.loc[target_indices, 'answer'] = trimmed_mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0dUZtMDyE_r"
      },
      "outputs": [],
      "source": [
        "submit.drop(columns=['date_time', 'hour', 'day', 'month', 'building_number'], inplace=True)\n",
        "output_file_path = f'{DATA_DIR}/final.csv'\n",
        "submit.to_csv(output_file_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dajjud7DmEn3",
        "VQv6915il2SD",
        "QHK7-ls-JJql",
        "1_31FzZPuE-z",
        "pjSdeOMphEsu",
        "KSCL3av7pYQy"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}